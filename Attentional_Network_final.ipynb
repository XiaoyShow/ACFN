{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attentional Correlation Filter Network for Adaptive Visual Tracking\n",
    "\n",
    "Jongwon Choi, 2017\n",
    "https://sites.google.com/site/jwchoivision/\n",
    "\n",
    "Python Code for Attentional Network\n",
    "\n",
    "Running environment:\n",
    "Linux Ubuntu 14.04.5 LTS\n",
    "ipython 5.1.0\n",
    "tensorflow 0.10.0rc0\n",
    "Cuda Release 8.0, V8.0.26\n",
    "\n",
    "When you use this code for your research, please refer the below reference.\n",
    "You can't use this code for any commercial purpose without author's agreement.\n",
    "If you have any question or comment, please contact to jwchoi.pil@gmail.com.\n",
    "\n",
    "Reference\n",
    "\n",
    "[1] Jongwon Choi, Hyung Jin Chang, Sangdoo Yun, Tobias Fischer, Yiannis Demiris, and Jin Young Choi, \"Attentional Correlation Filter Network for Adaptive Visual Tracking\", CVPR2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from os import listdir\n",
    "import scipy.io as sio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of neurons in each fully-connected layer\n",
    "num_hidden = 1024\n",
    "\n",
    "# Number of lstm modules\n",
    "num_lstm = 256\n",
    "\n",
    "# Recurrent size\n",
    "truncated_size_rnn = 10\n",
    "\n",
    "# Number of full-searching frames for initialization\n",
    "hierarchy_size = 5\n",
    "\n",
    "# Number of module trackers in correlation filter network\n",
    "num_module = 260"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variable initialization functions\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# place holders (input & output)\n",
    "x = tf.placeholder(\"float\", shape=[None, truncated_size_rnn, num_module])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, num_module])\n",
    "\n",
    "# For training\n",
    "y_gt_temp = tf.slice(x, [0,1,0], [tf.size(x)/truncated_size_rnn/num_module, truncated_size_rnn-1,num_module])\n",
    "y_gt = tf.reshape(tf.transpose(tf.concat(1, [y_gt_temp, tf.reshape(y_,[-1,1,num_module])]),[1,0,2]), [-1,num_module])\n",
    "y_gt_list = tf.split(0, truncated_size_rnn, y_gt)\n",
    "score_x = tf.reshape(tf.transpose(x, [1, 0, 2]), shape=[-1, num_module])\n",
    "x_list = tf.split(1, truncated_size_rnn, x)\n",
    "prev_score_x = tf.reshape(x_list[-1], shape=[-1, num_module])\n",
    "\n",
    "\n",
    "## Prediction Sub-network ##\n",
    "# LSTM layer\n",
    "h_fc2_split = tf.split(0, truncated_size_rnn, score_x)\n",
    "lstm_cell = rnn_cell.BasicLSTMCell(num_lstm, forget_bias=1.0, state_is_tuple=True)\n",
    "\n",
    "h_rnn, state = rnn.rnn(lstm_cell, h_fc2_split, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# fc1 + relu\n",
    "W_fc3 = weight_variable([num_lstm, num_hidden])\n",
    "b_fc3 = bias_variable([num_hidden])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_rnn[-1], W_fc3) + b_fc3)\n",
    "\n",
    "# fc2 + relu\n",
    "W_fc3_2 = weight_variable([num_hidden, num_hidden])\n",
    "b_fc3_2 = bias_variable([num_hidden])\n",
    "\n",
    "h_fc3_2 = tf.nn.relu(tf.matmul(h_fc3, W_fc3_2) + b_fc3_2)\n",
    "\n",
    "# fc3 + relu\n",
    "W_fc3_3 = weight_variable([num_hidden, num_hidden])\n",
    "b_fc3_3 = bias_variable([num_hidden])\n",
    "\n",
    "h_fc3_3 = tf.nn.relu(tf.matmul(h_fc3_2, W_fc3_3) + b_fc3_3)\n",
    "\n",
    "# fc4\n",
    "W_fc4 = weight_variable([num_hidden, num_module])\n",
    "b_fc4 = bias_variable([num_module])\n",
    "\n",
    "h_fc4 = tf.matmul(h_fc3_3, W_fc4) + b_fc4\n",
    "\n",
    "# the predicted scores from the prediction network\n",
    "pred_score = h_fc4\n",
    "\n",
    "\n",
    "\n",
    "## Selection Sub-network ##\n",
    "## Network for error prediction\n",
    "# fc1 + relu\n",
    "W_fc5 = weight_variable([num_module, num_hidden])\n",
    "b_fc5 = bias_variable([num_hidden])\n",
    "\n",
    "h_fc5 = tf.nn.relu(tf.matmul(h_fc4, W_fc5) + b_fc5)\n",
    "\n",
    "# fc2 + relu\n",
    "W_fc5_2 = weight_variable([num_hidden, num_hidden])\n",
    "b_fc5_2 = bias_variable([num_hidden])\n",
    "\n",
    "h_fc5_2 = tf.nn.relu(tf.matmul(h_fc5, W_fc5_2) + b_fc5_2)\n",
    "\n",
    "# fc3\n",
    "W_fc6 = weight_variable([num_hidden, num_module])\n",
    "b_fc6 = bias_variable([num_module])\n",
    "\n",
    "h_fc6 = tf.matmul(h_fc5_2, W_fc6) + b_fc6\n",
    "\n",
    "# pointer for predicted score\n",
    "curr_pred_score = pred_score\n",
    "\n",
    "## Network for top-k selection\n",
    "# binary result selecting the modules with high predicted score\n",
    "top_N = tf.placeholder(tf.int32) # number of the modules with high predicted score (parameter)\n",
    "top_N_val, top_N_idx = tf.nn.top_k(pred_score, k=top_N)\n",
    "sliced_top_N_val = tf.slice(top_N_val, [0, top_N-1], [tf.size(top_N_val)/top_N, 1])\n",
    "repeated_top_N_val = tf.tile(tf.reshape(sliced_top_N_val, [-1, 1]), [1, num_module])\n",
    "top_N_thresholded = tf.to_float(tf.greater_equal(pred_score, repeated_top_N_val))\n",
    "\n",
    "# Temporary (Not used)\n",
    "lambda_exp = tf.placeholder(\"float\")\n",
    "num_select = tf.placeholder(tf.int32)\n",
    "top_sel_val, top_sel_idx = tf.nn.top_k(tf.square(pred_score-y_), k=num_select)\n",
    "sliced_top_sel_val = tf.slice(top_sel_val, [0, num_select-1], [tf.size(top_sel_val)/num_select, 1])\n",
    "repeated_top_sel_val = tf.tile(tf.reshape(sliced_top_sel_val, [-1, 1]), [1, num_module])\n",
    "top_sel_thresholded = tf.to_float(tf.greater_equal(tf.square(pred_score-y_), repeated_top_sel_val))\n",
    "\n",
    "\n",
    "## Integration of the two results (error prediction + high predicted score)\n",
    "h_sel = tf.maximum(top_N_thresholded, tf.tanh(10*h_fc6))\n",
    "final_top_sel_val, final_top_sel_idx = tf.nn.top_k(h_sel, k=num_select)\n",
    "final_sliced_top_sel_val = tf.slice(final_top_sel_val, [0, num_select-1], [tf.size(final_top_sel_val)/num_select, 1])\n",
    "final_repeated_top_sel_val = tf.tile(tf.reshape(final_sliced_top_sel_val, [-1, 1]), [1, num_module])\n",
    "# pointer for binary selection of attentional modules\n",
    "final_top_sel_thresholded = tf.to_float(tf.greater_equal(h_sel, final_repeated_top_sel_val))\n",
    "h_sel_list = tf.split(0, truncated_size_rnn, h_sel)\n",
    "\n",
    "# final score estimation (for training)\n",
    "final_pred = tf.add(tf.mul(y_, h_sel), tf.mul(pred_score, 1-h_sel))\n",
    "\n",
    "# pointer for final score (for training)\n",
    "curr_final_pred = final_pred\n",
    "\n",
    "\n",
    "## tf saver\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## For training (not used here)\n",
    "# parameters for loss estimation\n",
    "learning_rate_part = tf.placeholder(\"float\")\n",
    "learning_rate = tf.placeholder(\"float\")\n",
    "lambda_sparse = tf.placeholder(\"float\")\n",
    "epsilon = tf.placeholder(\"float\")\n",
    "\n",
    "# Loss estimation\n",
    "error = tf.reduce_mean(tf.square(final_pred - y_)) + lambda_sparse*tf.reduce_mean(tf.log(epsilon+tf.abs(h_fc6)))\n",
    "error_part = tf.reduce_sum(tf.square(pred_score-y_))\n",
    "\n",
    "## Training pointer for selection sub-network\n",
    "var_list2 = [W_fc5, W_fc5_2,W_fc6, b_fc5, b_fc5_2, b_fc6]\n",
    "opt2 = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads = tf.gradients(error, var_list2)\n",
    "\n",
    "train_op = opt2.apply_gradients(zip(grads, var_list2))\n",
    "train_step = train_op\n",
    "\n",
    "## Training pointer for prediction sub-network\n",
    "train_step_part = tf.train.AdamOptimizer(learning_rate_part).minimize(error_part)\n",
    "\n",
    "# temporary. (for display)\n",
    "final_error_part = tf.reduce_mean(tf.square(curr_pred_score-y_))\n",
    "final_error = tf.reduce_mean(tf.square(curr_final_pred-y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Communication session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored from file\n",
      "Connected!\n",
      "prediction start!\n",
      "disconnect\n"
     ]
    }
   ],
   "source": [
    "# Load run-time library\n",
    "import time\n",
    "import socket\n",
    "import array\n",
    "\n",
    "# tf initialization & setting\n",
    "config = tf.ConfigProto()\n",
    "config=tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "# session start\n",
    "with tf.Session(config = config) as sess:\n",
    "    # network loading\n",
    "    saver.restore(sess, \"./model_VOT_full.ckpt\")\n",
    "    print(\"Model restored from file\")\n",
    "        \n",
    "    # Socket communication parameters\n",
    "    HOST = ''                 # Symbolic name meaning all available interfaces\n",
    "    PORT = 50005           # Arbitrary non-privileged port\n",
    "    \n",
    "    # socket initialization & connection\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.connect((HOST, PORT))\n",
    "\n",
    "    print 'Connected!'\n",
    "\n",
    "    # flag (0: no more sequences , 1: remaining sequences)\n",
    "    flag = 1\n",
    "    while flag==1:\n",
    "        \n",
    "        cnt = 0  #frame count\n",
    "        b_start_pred = -1  #-1: full search, 1: attentional search\n",
    "        # dummy variables\n",
    "        curr_h_sel = np.zeros([num_module])\n",
    "        curr_score = np.zeros([num_module])\n",
    "\n",
    "        # [socket] sending the current state (full search? attentional search?)\n",
    "        data_sending = array.array('f', [b_start_pred])\n",
    "        coded_data = data_sending.tostring()\n",
    "        s.sendall(coded_data)\n",
    "\n",
    "        # [socket] recieving the estimated scores for all modules\n",
    "        data = s.recv(1024)\n",
    "        data_cast1 = array.array('f', data)\n",
    "        data = s.recv(1024)\n",
    "        data_cast2 = array.array('f', data)\n",
    "        data_cast = np.concatenate((np.reshape(data_cast1, [1,1,-1]), np.reshape(data_cast2, [1,1,-1])), axis = 2)\n",
    "\n",
    "        # score normalization\n",
    "        max_scores = np.max(data_cast, axis=2, keepdims=True)\n",
    "        min_scores = np.min(data_cast, axis=2, keepdims=True)\n",
    "        data_cast = (data_cast - min_scores) / (max_scores - min_scores)\n",
    "\n",
    "        # attentional network input\n",
    "        x_temp = data_cast\n",
    "        \n",
    "\n",
    "        # for every frame\n",
    "        while 1:\n",
    "\n",
    "            # for initial frames with full search\n",
    "            if b_start_pred < 0:\n",
    "                # state change\n",
    "                if cnt > truncated_size_rnn + hierarchy_size:\n",
    "                    b_start_pred = 1\n",
    "                    print \"prediction start!\"\n",
    "                # [socket] sending the current state of full search\n",
    "                else:                   \n",
    "                    data_sending = array.array('f', [0])\n",
    "                    coded_data = data_sending.tostring();\n",
    "                    s.sendall(coded_data)\n",
    "\n",
    "            # for initial frames with full search\n",
    "            if b_start_pred < 0:\n",
    "                # [socket] recieving the scores of the entire modules\n",
    "                data = s.recv(1024)\n",
    "                data_cast1 = array.array('f', data)\n",
    "                data = s.recv(1024)\n",
    "                data_cast2 = array.array('f', data)\n",
    "                data_cast = np.concatenate((np.reshape(data_cast1, [1,1,-1]), np.reshape(data_cast2, [1,1,-1])), axis = 2)\n",
    "\n",
    "                # score normalization\n",
    "                max_scores = np.max(data_cast, axis=2, keepdims=True)\n",
    "                min_scores = np.min(data_cast, axis=2, keepdims=True)\n",
    "                data_cast = (data_cast - min_scores) / (max_scores - min_scores)\n",
    "\n",
    "                # input setting for attentional network\n",
    "                x_temp = np.concatenate((x_temp, data_cast), axis = 1)\n",
    "\n",
    "                # Score stack truncation\n",
    "                shs = np.shape(x_temp)\n",
    "                if shs[1] > truncated_size_rnn:\n",
    "                    x_temp = x_temp[:, 1:, :]\n",
    "\n",
    "            # for last frames with attentional search\n",
    "            else:\n",
    "\n",
    "                # Run the attentional network\n",
    "                feed_dicts = {x: x_temp, top_N:13, num_select:52}\n",
    "                output = sess.run([curr_pred_score, final_top_sel_thresholded], feed_dict=feed_dicts)\n",
    "\n",
    "                # Recover the normalized output scores\n",
    "                curr_score = (output[0] * (max_scores - min_scores)) + min_scores\n",
    "                curr_score = np.reshape(curr_score, [-1])\n",
    "                \n",
    "                # binary selection vector\n",
    "                curr_h_sel = output[1]\n",
    "                idxs = np.argwhere(curr_h_sel == 1)\n",
    "                idxs = np.reshape(idxs[:,1], [-1])\n",
    "\n",
    "                # [socket] sending the selection result\n",
    "                data_sending = array.array('f', idxs)\n",
    "                coded_data = data_sending.tostring()          \n",
    "                s.sendall(coded_data)\n",
    "\n",
    "                # [socket] recieving the estimated scores of the selected modules\n",
    "                data = s.recv(1024)\n",
    "                data_cast = array.array('f', data)\n",
    "                \n",
    "                # For next sequence\n",
    "                if(data_cast[0] < 0):\n",
    "                    print \"next sequence\"\n",
    "                    break\n",
    "                    \n",
    "                # Finished\n",
    "                if(data_cast[0] > 1):\n",
    "                    s.close()\n",
    "                    flag = 0\n",
    "                    print \"disconnect\"                    \n",
    "                    break\n",
    "                                    \n",
    "                # Final score estimation (integration)\n",
    "                curr_score[idxs] = data_cast                \n",
    "                curr_score = np.reshape(curr_score, [1,1,-1])\n",
    "                \n",
    "                # Final score normalization\n",
    "                max_scores = np.max(curr_score, axis=2, keepdims=True)\n",
    "                min_scores = np.min(curr_score, axis=2, keepdims=True)\n",
    "                curr_score = (curr_score - min_scores) / (max_scores - min_scores)\n",
    "\n",
    "                # Final score input setting\n",
    "                x_temp = np.concatenate((x_temp, curr_score), axis = 1)\n",
    "                \n",
    "                # Score stack truncation\n",
    "                shs = np.shape(x_temp)\n",
    "                if shs[1] > truncated_size_rnn:\n",
    "                    x_temp = x_temp[:, 1:, :]\n",
    "\n",
    "            # next frame\n",
    "            cnt = cnt + 1\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
